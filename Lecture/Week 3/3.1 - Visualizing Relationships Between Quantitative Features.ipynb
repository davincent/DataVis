{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Relationships Between Quantitative Features\n",
    "\n",
    "So far we've looked at the distribution of single features, the distribution of two categorical features, and how to visualize differences between groups.  In this lesson we'll discuss how to look at the relationships between two quantitative features.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Healthcare Dataset:\n",
    "\n",
    "How do personal features like age, BMI, smoking status, diet and exercise effect how much you pay for healthcare? Do older people, in general, pay more for healthcare?  How do other factors like BMI and smoking effect your healthcare costs?  We'll find the answers to these questions in this lesson.\n",
    "\n",
    "Let's import pandas, matplotlib and seaborn and read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we are looking at the relationships between quantitative features.  Which three features are quantitative and continuous?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classic figure for examining the relationship between two quantitative features is called a scatterplot.  You've probably made them before.  We graph the value of one feature on the x-axis and the value of the other feature on the y-axis.  The pattern formed by the data tells us about the relationship between the two features.\n",
    "\n",
    "To start, we are going to graph the relationship between age (on the x-axis) and healthcare charges (on the y-axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In general, we see that healthcare chargest tend to increase as people get older.  However, that relationship isn't perfect.  There's a lot of varibility in how much individuals of the same age pay for healthcare.\n",
    "\n",
    "Because the data points fall roughly in a line, we can represent the relationship between the two features with a linear model.  You'll talk a lot more about exactly how this works - how the model is fit to the data,how to tell if it's a good model or not - in the machine learning course.\n",
    "\n",
    "Let's see if we can figure out what other features in our data might explain some of this variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smokers seem to have consistently higher healthcare charges than nonsmokers.  What about BMI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there's a mix of people with different BMIs all throughout the data.  What if we categorize BMI?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope - not really!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "But we're just running on vibes.  How can we make this more rigorous?\n",
    "\n",
    "In data science, we are often interested in developing a model of our data.  A model is a mathematical representation of the general relationship present in our data.  \n",
    "\n",
    "**If the pattern of our data is roughly a line (either in the positive or negative direction) we can represent our data using a line - aka a linear model - aka linear regression.**  Because our data is clearly in three different groups, it makes sense to represent our data using three lines rather than one.  \n",
    "\n",
    "You'll learn much more about the ins and outs of this procedure, known as linear regression, in the machine learning course.  For now, it's enough to see a visual representation of using a model to summarize the relationship of age to healthcare costs for each group.  \n",
    "\n",
    "**Ideally your linear regression line should run right through the middle of your data, crossing as many points as possible.  There should be an approximately equal number of points above and below the regression line.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We couldn't use this model to perfectly predict the healthcare costs for an individual at a specific age.  However, if you were a healthcare economist, it could give you a ballpark figure how how much you expect costs to go up as people age depending on if they were at a low, medium or high claim risk.\n",
    "\n",
    "In the words of the famous statistician George Box (who is different from the boxplot guy, John Tukey):\n",
    "\n",
    "**\"All models are wrong, but some are useful.\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But how exactly do we determine if this model is a good fit or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We generally measure model fit with something called R-squared.  R-squared ranges from 0 - 1 (sometimes represented from 0 % - 100 %).  There are no strict rules for what makes a \"good\" R-squared or a \"bad\" R-squared (more vibes) but the closer you get to 1 (or 100%) the better the model fits.\n",
    "\n",
    "The definition of R-squared is \"The percent of variability in the data that is explained by the model.\"  Having 100% of your data explained by the model is a good thing.\n",
    "\n",
    "**You are going to learn a different way to do this calculation in the next class.  That's okay.  Sometimes there's more than one way to do something.  The interpretation of R-squared in both cases is the same.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the model improved if we add in smoking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about BMI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about Exercise Frequency and Diet Quality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When is a line not a good fit for the data?\n",
    "\n",
    "Linear models are a powerful data analysis tool.  They do a great job in a lot of situations.  However, it's important to be on the lookout for times when a linear model is a poor fit for your data.  Making a visualization is often the easiest way to check for model fit issues ahead of time.\n",
    "\n",
    "A linear model is not a good fit for your data if:\n",
    "\n",
    "**1. Your data is made up of more than one distinct group.**\n",
    "\n",
    "One single line won't do a good job capturing the relationships for the individual groups.  Here the regression line passes through almost none of the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. When there are outliers that fall far outside the normal range of the data.**\n",
    "\n",
    "Here's an example plotting the relationship of age and fare paid in the Titanic data.  See those two people who were a little younger than 40 and paid 500 pounds for their tickets?  Those are outliers.  This model doesn't fit well because there are way more points above the line than below it, and there are big outliers at the top of the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**3. When there is a curved rather than linear relationship in the data.**\n",
    "\n",
    "Here is a plot of the cumulative revenue each week the film was showing.  You can see that the relationship of cumulative revenue to the number of weeks the film had been shown is curved rather than a straight line.  There are mathematical ways to transform a curved relationship into a straight line relationship, but we might not know one is present if we don't visualize the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# How to tackle nonlinear relationships\n",
    "\n",
    "This is something you'll dig into in much more detail in the machine learning class, but it's possible to model the relationship between two features with a non-linear relationship.\n",
    "Often this involves some trial and error on the part of the data scientist.  In this example, we look at modeling the relationship between temperature and quality in a manufacturing process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exponential Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# Function to apply polynomial regression and plot results\n",
    "def apply_and_plot_polynomial_regression(degree, X_train, X_test, y_train, y_test):\n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "\n",
    "    # Fit a linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred = model.predict(X_test_poly)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(X_train, y_train, alpha=0.5, color='darkgreen')\n",
    "    plt.scatter(X_test, y_test, alpha=0.5, color='darkgreen')\n",
    "    \n",
    "    # Plot the model\n",
    "    X_fit = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
    "    y_fit = model.predict(poly.transform(X_fit))\n",
    "    plt.plot(X_fit, y_fit, color='red', label=f'Polynomial Degree {degree} (R2: {r2:.2f})')\n",
    "\n",
    "    plt.title(f'Polynomial Regression (Degree {degree})')\n",
    "    plt.xlabel('Temperature (°C)')\n",
    "    plt.ylabel('Quality Rating')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return r2\n",
    "\n",
    "manufacturing_data = pd.read_csv('assets/manufacturing.csv', encoding='ISO-8859-1')\n",
    "manufacturing_data.rename(columns={'Temperature (Â°C)': 'Temperature (°C)'}, inplace=True)\n",
    "\n",
    "# Preparing the data\n",
    "X = manufacturing_data[['Temperature (°C)']].values\n",
    "y = manufacturing_data['Quality Rating'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply and plot polynomial regression for different degrees\n",
    "degrees = [2, 3, 4, 5]\n",
    "for degree in degrees:\n",
    "    apply_and_plot_polynomial_regression(degree, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logarithmic Relationship\n",
    "\n",
    "In this example, we look at the relationship between the carat value and cost of a diamond.\n",
    "\n",
    "Before log transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the diamonds dataset\n",
    "diamonds = sns.load_dataset('diamonds')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x = 'carat', y='price', data=diamonds)\n",
    "plt.title('Carat vs. Price')\n",
    "plt.xlabel('Carat')\n",
    "plt.ylabel('Price')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with log transformations to find the best linear relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carat vs log of price\n",
    "\n",
    "diamonds['log_carat'] = np.log(diamonds['carat'])\n",
    "diamonds['log_price'] = np.log(diamonds['price'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x = 'carat', y='log_price', data=diamonds)\n",
    "plt.title('Carat vs. Log(Price)')\n",
    "plt.xlabel('Carat')\n",
    "plt.ylabel('Log(Price)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Price vs log of carat\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x = 'log_carat', y='price', data=diamonds)\n",
    "plt.title('Log(Carat) vs. Price')\n",
    "plt.xlabel('Log(Carat)')\n",
    "plt.ylabel('Price')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Both log transformed\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x = 'log_carat', y='log_price', data=diamonds)\n",
    "plt.title('Log(Carat) vs. Log(Price)')\n",
    "plt.xlabel('Log(Carat)')\n",
    "plt.ylabel('Log(Price)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OK\n",
    "With these tools you should be able to visualize the relationship between two quantitative features and determine if other featuers in your dataset impact that relationship.  You can determine if a linear model is a good fit for the data by making a regression plot using Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
